{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import the libraries"
      ],
      "metadata": {
        "id": "fSCT8ZfJ0F82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dDja-IW31wfN"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# url = 'https://raw.githubusercontent.com/anhphuongnguyenquynh/ML-DL-NLP-AI_Code_Practices/main/deep_learning/data/temperature.csv'\n",
        "# temperature = pd.read_csv(url)\n",
        "# temperature.head()"
      ],
      "metadata": {
        "id": "jgz4UZo71StA"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare data"
      ],
      "metadata": {
        "id": "Kn3TMMCM0ICQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentences (textual data) and their sentiment labels (1 for positive and 0 for negative)\n",
        "sentences = [\"i love this movie\", \"this film is amazing\", \"i didn't like it\", \"it was terrible\"]\n",
        "sentiment = [1, 1, 0, 0]"
      ],
      "metadata": {
        "id": "mogxwGrr2kGd"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create vocabulary\n",
        "Create simple vocabulary to represent words as indices.\n",
        "Convert words in our sentences to numbers. Fed as input to neural network."
      ],
      "metadata": {
        "id": "FSvIhia80JXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple vocabulary to represent words as indices\n",
        "vocab = {\"<PAD>\": 0, \"i\": 1, \"love\": 2, \"this\": 3, \"movie\": 4, \"film\": 5, \"is\": 6, \"amazing\": 7, \"didn't\": 8, \"like\": 9, \"it\": 10, \"was\": 11, \"terrible\": 12}"
      ],
      "metadata": {
        "id": "m1Cw6gSl3zTe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenize, Encode, Pad sentences"
      ],
      "metadata": {
        "id": "ctpD2vjb0LAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sentences = [[vocab[word] for word in sentence.split()] for sentence in sentences]\n",
        "max_length = max([len(sentence) for sentence in encoded_sentences])\n",
        "padded_sentences = [sentence + [vocab[\"<PAD>\"]] * (max_length - len(sentence)) for sentence in encoded_sentences]"
      ],
      "metadata": {
        "id": "QH4EB1w0EkdU"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx-aqN_LFQ0q",
        "outputId": "15e528f8-d5ea-4096-f8e7-ef68f6b8ddf0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4], [3, 5, 6, 7], [1, 8, 9, 10], [10, 11, 12]]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx2pyBuGtcEE",
        "outputId": "60b3e350-b59b-4b13-acc3-b3d8f2428e7c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laBT3aaUticb",
        "outputId": "9e93f503-482a-4dbf-ff9a-19ece91ec2a8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4], [3, 5, 6, 7], [1, 8, 9, 10], [10, 11, 12, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convert data to tensors"
      ],
      "metadata": {
        "id": "WmCjK96Y0ORi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.LongTensor(padded_sentences)\n",
        "labels = torch.FloatTensor(sentiment)"
      ],
      "metadata": {
        "id": "2E8h8L8_t4Iu"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcj1WTjgt-qs",
        "outputId": "cb689c0b-c401-443e-a13f-20ddbabf5ce2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 3,  5,  6,  7],\n",
            "        [ 1,  8,  9, 10],\n",
            "        [10, 11, 12,  0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYXZVfJct_83",
        "outputId": "919af470-fad1-44e9-edb6-58c6cff55db9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM Model"
      ],
      "metadata": {
        "id": "zksqS7ZL0RRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "    super(SimpleLSTM, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    output, (hidden, _) = self.lstm(embedded)\n",
        "    logits = self.fc(hidden.squeeze(0))\n",
        "    return logits"
      ],
      "metadata": {
        "id": "z2p6NDG1uCvg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the model"
      ],
      "metadata": {
        "id": "N3UKg6bA0cOA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "_RttMj6jz940"
      },
      "outputs": [],
      "source": [
        "model = SimpleLSTM(vocab_size = len(vocab), embedding_dim = 10, hidden_dim = 32, output_dim = 1)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  predictions = model(inputs.t()).squeeze(1) #inputs [batch, max_length] -> input of lstm pytorch\n",
        "  loss = criterion(predictions, labels)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0cgygUay25I",
        "outputId": "ab8befa6-e317-4e13-cdbb-c193fa222ee0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 0.6397\n",
            "Epoch 20/100, Loss: 0.5903\n",
            "Epoch 30/100, Loss: 0.5260\n",
            "Epoch 40/100, Loss: 0.4412\n",
            "Epoch 50/100, Loss: 0.3358\n",
            "Epoch 60/100, Loss: 0.2218\n",
            "Epoch 70/100, Loss: 0.1256\n",
            "Epoch 80/100, Loss: 0.0678\n",
            "Epoch 90/100, Loss: 0.0399\n",
            "Epoch 100/100, Loss: 0.0264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test the model"
      ],
      "metadata": {
        "id": "zRwARIqp3yDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  test_sentences = [\"i love this movie\", \"i didn't like it\"]\n",
        "  test_encoded_sentences = [[vocab[word] for word in sentence.split()] for sentence in test_sentences]\n",
        "  padded_test_sentences = [sentence + [vocab[\"<PAD>\"]] * (max_length - len(sentence)) for sentence in test_encoded_sentences]\n",
        "  test_inputs = torch.LongTensor(padded_test_sentences)\n",
        "  test_predictions = torch.sigmoid(model(test_inputs.t()).squeeze(1))\n",
        "  print(\"Test prdictions:\", test_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTYzrOEo3wZ9",
        "outputId": "181052d0-88b6-44fc-cae8-e8bd975b2f2b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test prdictions: tensor([0.9798, 0.0178])\n"
          ]
        }
      ]
    }
  ]
}